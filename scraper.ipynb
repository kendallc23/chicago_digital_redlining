{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install/Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kendall/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import jsonlines\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "#from seleniumwire import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraper Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Set up chrome driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_undetected_driver():\n",
    "    # Create ChromeOptions instance\n",
    "    chrome_options = uc.ChromeOptions()\n",
    "\n",
    "    # Enable performance logging\n",
    "    chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})\n",
    "\n",
    "    # Add any other arguments you need\n",
    "    chrome_options.add_argument(\"--enable-logging\")\n",
    "\n",
    "    # Create the undetected ChromeDriver instance\n",
    "    driver = uc.Chrome(options=chrome_options, version_main=126)\n",
    "\n",
    "    # Set timeouts\n",
    "    driver.set_script_timeout(30)\n",
    "    driver.set_page_load_timeout(30)\n",
    "\n",
    "    # Return the webdriver instance we just created\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Query Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address search function\n",
    "\n",
    "def search_address(driver, address, max_attempts = 10): \n",
    "    # 1. Set up loop to allow for multiple query attempts in order to circumvent pop ups\n",
    "    for attempt in range(max_attempts):\n",
    "        try: \n",
    "            # 2. Locate Address Search Bar\n",
    "            address_input = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.ID, \"input-addressInput\"))\n",
    "                )\n",
    "            \n",
    "            \n",
    "            # 3. Enter address and double check that search input matches function input\n",
    "            address_input.send_keys(address)\n",
    "            entered_text = address_input.get_attribute(\"value\")\n",
    "            print(entered_text)\n",
    "            \n",
    "            if entered_text != address:\n",
    "                print(f\"Entered Text: {entered_text}\")\n",
    "                print(f\"Address: {address}\")\n",
    "                print(\"address entered incorrectly\")\n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "                    driver.refresh()  # Refresh the page and try again\n",
    "                    continue # make sure to go to the next attampt after this (is this necessary?)\n",
    "                else:\n",
    "                    print(\"Max attempts reached. Could not enter address.\")\n",
    "                    return False\n",
    "            \n",
    "            # 4. Submit Address\n",
    "            address_input.send_keys(Keys.RETURN)\n",
    "        \n",
    "            # 5. Return True if address is sucessfully submitted\n",
    "            return True\n",
    "        \n",
    "        # 5. Retry or return false if pop up occurs\n",
    "        except ElementNotInteractableException:\n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "                    driver.refresh()  # Refresh the page and try again\n",
    "                else:\n",
    "                    print(\"Max attempts reached. Could not enter address.\")\n",
    "                    return False\n",
    "                  \n",
    "        # QUESTION: IF THE PAGE DID NOT LOAD (ACCESS DENIED), IS THERE A WAY TO RELOAD AND TRY AGAIN\n",
    "        # MAYBE CALL SET UP DRIVER FUNCTION? \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collect API or Session Storage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather session storage data where applicable\n",
    "def get_session_storage_data(driver, key):\n",
    "  script = f\"return window.sessionStorage.getItem('{key}');\"\n",
    "  return driver.execute_script(script) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_api_response(driver, api_name=\"service-address-validation\", time_out=60):\n",
    "    start_time = time.time()\n",
    "    request_response_pairs = {}\n",
    "\n",
    "    while time.time() - start_time < time_out:\n",
    "        try:\n",
    "            logs = driver.get_log(\"performance\")\n",
    "            for entry in logs:\n",
    "                log = json.loads(entry['message'])['message']\n",
    "                if log['method'] == 'Network.requestWillBeSent':\n",
    "                    params = log.get('params', {})\n",
    "                    request = params.get('request', {})\n",
    "                    request_url = request.get('url', '')\n",
    "                    if api_name in request_url.lower():\n",
    "                        request_id = log[\"params\"][\"requestId\"]\n",
    "                        request_response_pairs[request_id] = {'request': request_url}\n",
    "                elif log['method'] == 'Network.responseReceived':\n",
    "                    response_request_id = log.get('params', {}).get('requestId')\n",
    "                    if response_request_id in request_response_pairs:\n",
    "                        request_response_pairs[response_request_id]['response'] = log.get('params', {})\n",
    "\n",
    "            # Check if we have any complete request-response pairs\n",
    "            for request_id, data in request_response_pairs.items():\n",
    "                if 'request' in data and 'response' in data:\n",
    "                    try:\n",
    "                        response = driver.execute_cdp_cmd('Network.getResponseBody', {'requestId': request_id})\n",
    "                        response_body = response.get(\"body\", \"\")\n",
    "                        return json.loads(response_body)\n",
    "                    except Exception:\n",
    "                        # If there's an error getting the response body, immediately try session storage\n",
    "                        break\n",
    "\n",
    "            # If we haven't returned by now, try session storage\n",
    "            session_storage_data = get_session_storage_data(driver, \"qualificationInfo\")\n",
    "            if session_storage_data:\n",
    "                return json.loads(session_storage_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing logs: {type(e).__name__}\")\n",
    "\n",
    "    print(\"No API response or session storage data found within the timeout period\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close matches often occur when an address is given without a subaddress. \n",
    "# this function selects a random subaddress and returns an address including the subaddress to requery\n",
    "def handling_close_matches(data):\n",
    "  alt_add = data[\"content\"]['alternateAddress']\n",
    "  if type(alt_add) == list: # randomly select an alretnate address to query \n",
    "    #-> else, there is just one dictionary for one alternate address\n",
    "    index = random.randint(0, len(alt_add) - 1)\n",
    "    print(index)\n",
    "    alt_add = data[\"content\"]['alternateAddress'][index]\n",
    "  \n",
    "  str_num = alt_add.get(\"streetNr\", \"\")\n",
    "  str_dir = alt_add.get(\"streetDirection\", \"\")\n",
    "  str_name = alt_add.get(\"streetName\", \"\")\n",
    "  str_type = alt_add.get(\"streetType\", \"\")\n",
    "  city = alt_add.get(\"city\", \"\")\n",
    "  state = alt_add.get(\"stateOrProvince\", \"\")\n",
    "  postcode = alt_add.get(\"postcode\", \"\")\n",
    "  \n",
    "  try: \n",
    "    sub_address = alt_add.get('subAddress', \"\")\n",
    "    return str_num + \" \" + str_dir + \" \" + str_name + \" \" + str_type + \" \" + sub_address + \", \" + city + \", \" + state + \" \" + postcode\n",
    "  except KeyError:\n",
    "    try:\n",
    "      sub_unit_type = data[\"content\"]['alternateAddress']['geographicSubAddress']['subUnitType']\n",
    "      unit_type = sub_unit_type.get(\"addrType\")\n",
    "      unit_val = sub_unit_type.get(\"value\")\n",
    "      return str_num + \" \" + str_dir + \" \" + str_name + \" \" + str_type + \" \" + unit_type + \" \" + unit_val + \", \" + city + \", \" + state + \" \" + postcode\n",
    "    except KeyError:\n",
    "      return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for writing results as dictionaries to JSON lines (jsonl) files\n",
    "def append_result_to_jsonl(results_dict, filename = \"att_fiber_availability_data.jsonl\"):\n",
    "  with open(filename, \"a\") as f:\n",
    "    json.dump(results_dict, f)\n",
    "    f.write(\"\\n\")\n",
    "  print(f\"Result appended to {filename}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses json api response to retain only necessary data and writes to a json file containing the output \n",
    "\n",
    "def parse_and_save_available_resp(address, driver, output_file, api_name = \"service-address-validation\", time_out = 30):\n",
    "  invalid = False\n",
    "  \n",
    "  try: \n",
    "  \n",
    "    # 1. Query address and collect response indicating fiber availability\n",
    "    data = collect_api_response(driver, api_name, time_out)\n",
    "  \n",
    "    if data:\n",
    "      # 2. Initialize data values\n",
    "      fiber_available = False\n",
    "      services_enabled = None \n",
    "      existing_services = None\n",
    "      upload_speed = 0\n",
    "      download_speed = 0\n",
    "      \n",
    "      # 2.1. Check for non matches/addresses not in system\n",
    "      if data[\"content\"][\"status\"] == \"nomatch\":\n",
    "        invalid_add = address\n",
    "        invalid = True\n",
    "        return [invalid_add, invalid]\n",
    "      \n",
    "      # 2.2. Check for close matches --> may help with issues of omitted subaddresses\n",
    "      if data[\"content\"][\"status\"] == \"closematch-mdu\" or data[\"content\"][\"status\"] == \"closematch\":\n",
    "        new_add = handling_close_matches(data)\n",
    "        \n",
    "        if not new_add:\n",
    "          invalid = True\n",
    "          invalid_add = address\n",
    "          return [invalid_add, invalid] # no alternate address found\n",
    "        \n",
    "        return [new_add, invalid] #invalid = false; this address will be requeried, if necessary\n",
    "        \n",
    "        \n",
    "      # 3. Check serviceQualification section for availability indicators\n",
    "      for cat in data[\"content\"][\"serviceQualification\"]:\n",
    "        if cat[\"category\"][\"name\"] == \"INTERNET\":\n",
    "          for service in cat[\"category\"][\"services\"]:\n",
    "            #print(type(service))\n",
    "            if service[\"name\"] == \"FIBER\":\n",
    "              fiber_available = service[\"QualificationResult\"] == \"qualified\"\n",
    "              upload_speed = service.get('MaxUploadSpeedMbps', 0)\n",
    "              download_speed = service.get('MaxDownloadSpeedMbps', 0)\n",
    "              break\n",
    "      \n",
    "\n",
    "      # 4. Check additional fields relating to fiber availability and adoption\n",
    "      services_enabled = data['content'].get('enabled', [])\n",
    "      existing_services = data['content'].get('existingServices', [])\n",
    "\n",
    "      # 5 Compile results as a dictionary\n",
    "      results_dict = {\n",
    "              'address': address,\n",
    "              'fiber_available': fiber_available,\n",
    "              'services_enabled': services_enabled,\n",
    "              'existing_services': existing_services,\n",
    "              'upload_speed': upload_speed,\n",
    "              'download_speed': download_speed\n",
    "          }\n",
    "      \n",
    "      # 6. Write Results to a JSON File\n",
    "      print(\"appending data to outputfile...\")\n",
    "      append_result_to_jsonl(results_dict, filename = output_file)\n",
    "      return [None, None]\n",
    "  \n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {type(e).__name__}, {str(e)}\")\n",
    "    invalid = True\n",
    "    return [1, invalid]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load addresses from files instead of lists and back up results\n",
    "def load_addresses(filename):\n",
    "    addresses = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                address = json.loads(line.strip())\n",
    "                if isinstance(address, str):\n",
    "                    addresses.append(address)\n",
    "                elif isinstance(address, dict) and 'address' in address:\n",
    "                    addresses.append(address['address'])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
    "    return addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Webscraper Function built from previous helpers--> handles multiple addresses and saves results to a json file\n",
    "\n",
    "def att_web_scraper(address_file, output_file_1, output_file_2):\n",
    "  #print(\"Beginning Web scraper...\")\n",
    "  \n",
    "  # 0. Initialize an empty list of addresses that need to be retried due to query errors\n",
    "  address_list =  load_addresses(address_file)\n",
    "  adds_to_requery = []\n",
    "  invalid_adds = [] # may be necessary to track addresses that are not in the system\n",
    "  \n",
    "  # 1. Iterate through addresses in address list\n",
    "  adds_successfully_queried = 0\n",
    "  for i, address in enumerate(address_list):\n",
    "    #driver.refresh()\n",
    "   \n",
    "    print(f\"Processing address number {i}: {address}\")\n",
    "    driver = None\n",
    "  \n",
    "    try:\n",
    "      # 2. Initialize Driver\n",
    "     \n",
    "      try:\n",
    "          driver = setup_undetected_driver()\n",
    "          driver.get(\"https://www.att.com/internet/fiber/\")\n",
    "          print(\"New Driver initialized\")\n",
    "      except TimeoutException:\n",
    "          print(f\"Timeout occurred while loading the initial page for address {address}\")\n",
    "          adds_to_requery.append(address)\n",
    "          append_result_to_jsonl(address, output_file_2)\n",
    "          continue\n",
    "        \n",
    "      # 3. Query Addresses\n",
    "      if not search_address(driver, address):\n",
    "        adds_to_requery.append(address)\n",
    "        append_result_to_jsonl(address, output_file_2)\n",
    "        #print(\"Address search failed. Try again\")\n",
    "        #driver.refresh()\n",
    "        continue\n",
    "      \n",
    "      # 4. Gather and parse fiber data\n",
    "      print(\"Address successfully queried\")\n",
    "      \n",
    "      parsing_result = parse_and_save_available_resp(address, driver, output_file_1)\n",
    "      print(\"parsing result:\", parsing_result)\n",
    "      \n",
    "      if parsing_result[0]:\n",
    "        if parsing_result[1] and parsing_result[0] != 1:\n",
    "          print(\"Invalid address\")\n",
    "          invalid_adds.append(parsing_result[0])\n",
    "          continue\n",
    "        elif parsing_result[1] and parsing_result[0] == 1:\n",
    "          print(\"Unexpected error. Retry Address.\")\n",
    "          adds_to_requery.append(address)\n",
    "          append_result_to_jsonl(address, output_file_2)\n",
    "        else:\n",
    "          print(\"address modified for requerying\")\n",
    "          adds_to_requery.append(parsing_result[0])\n",
    "          append_result_to_jsonl(address, output_file_2)\n",
    "          continue\n",
    "          \n",
    "      else:\n",
    "        print(\"parsed network/session storage data\")\n",
    "        adds_successfully_queried += 1\n",
    "        #driver.refresh()\n",
    "        continue\n",
    "       \n",
    "    except Exception  as e:\n",
    "      print(\"reached web scraper except block\")\n",
    "      print(\"An unexpected error occurred.\")\n",
    "      adds_to_requery.append(address)\n",
    "      append_result_to_jsonl(address, output_file_2)\n",
    "      #driver.refresh()\n",
    "      continue\n",
    "    \n",
    "    finally:\n",
    "      if driver:\n",
    "                try:\n",
    "                    driver.quit()\n",
    "                    print(\"Browser closed successfully\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error closing browser: {str(e)}\")\n",
    "                    \n",
    "    if i < len(address_list) - 1:  # Don't wait after the last address\n",
    "            print(\"Waiting before processing the next address...\")\n",
    "            wait_time_sec = random.randint(3, 14)\n",
    "            time.sleep(wait_time_sec)\n",
    "    \n",
    "  # Ensure driver is always closed, even if an exception occurs\n",
    "  if driver:\n",
    "    driver.quit()\n",
    "    print(\"Driver closed\")\n",
    "  \n",
    "  print(\"Finished all address queries!\")\n",
    "  return adds_to_requery, invalid_adds, adds_successfully_queried"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
